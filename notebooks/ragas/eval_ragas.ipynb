{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach to the same event-loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaurya/projects/S2QA/.conda/lib/python3.10/site-packages/langchain/__init__.py:24: UserWarning: Importing BasePromptTemplate from langchain root module is no longer supported.\n",
      "  warnings.warn(\n",
      "/Users/shaurya/projects/S2QA/.conda/lib/python3.10/site-packages/langchain/__init__.py:24: UserWarning: Importing PromptTemplate from langchain root module is no longer supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "import pandas as pd\n",
    "from llama_hub.semanticscholar.base import SemanticScholarReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaurya/projects/S2QA/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "from ragas.llama_index import evaluate\n",
    "\n",
    "from ragas.metrics.critique import harmfulness\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    "    harmfulness,\n",
    "]\n",
    "\n",
    "s2reader = SemanticScholarReader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:19<00:00, 19.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [harmfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>harmfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is a paragraph retrieval dataset?</td>\n",
       "      <td>[Multi-Hop Paragraph Retrieval for Open-Domain...</td>\n",
       "      <td>A paragraph retrieval dataset is a dataset tha...</td>\n",
       "      <td>[A paragraph retrieval dataset is a resource u...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.937075</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some examples of paragraph retrieval ...</td>\n",
       "      <td>[Multi-Hop Paragraph Retrieval for Open-Domain...</td>\n",
       "      <td>SQuAD-Open and HotpotQA are examples of paragr...</td>\n",
       "      <td>[Examples of paragraph retrieval datasets incl...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why are paragraph retrieval datasets important?</td>\n",
       "      <td>[Analysing the Resourcefulness of the Paragrap...</td>\n",
       "      <td>Paragraph retrieval datasets are important bec...</td>\n",
       "      <td>[Paragraph retrieval datasets are key to impro...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.991355</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the MSMARCO dataset used for?</td>\n",
       "      <td>[Teaching Smaller Language Models To Generalis...</td>\n",
       "      <td>The context information does not provide any i...</td>\n",
       "      <td>[MSMARCO, also known as Microsoft Machine Read...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.717319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can paragraph retrieval datasets help in m...</td>\n",
       "      <td>[Analysing the Resourcefulness of the Paragrap...</td>\n",
       "      <td>Paragraph retrieval datasets can help in machi...</td>\n",
       "      <td>[Paragraph retrieval datasets help in machine ...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.978917</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0             What is a paragraph retrieval dataset?   \n",
       "1  What are some examples of paragraph retrieval ...   \n",
       "2    Why are paragraph retrieval datasets important?   \n",
       "3              What is the MSMARCO dataset used for?   \n",
       "4  How can paragraph retrieval datasets help in m...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Multi-Hop Paragraph Retrieval for Open-Domain...   \n",
       "1  [Multi-Hop Paragraph Retrieval for Open-Domain...   \n",
       "2  [Analysing the Resourcefulness of the Paragrap...   \n",
       "3  [Teaching Smaller Language Models To Generalis...   \n",
       "4  [Analysing the Resourcefulness of the Paragrap...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  A paragraph retrieval dataset is a dataset tha...   \n",
       "1  SQuAD-Open and HotpotQA are examples of paragr...   \n",
       "2  Paragraph retrieval datasets are important bec...   \n",
       "3  The context information does not provide any i...   \n",
       "4  Paragraph retrieval datasets can help in machi...   \n",
       "\n",
       "                                       ground_truths  faithfulness  \\\n",
       "0  [A paragraph retrieval dataset is a resource u...          0.75   \n",
       "1  [Examples of paragraph retrieval datasets incl...          0.00   \n",
       "2  [Paragraph retrieval datasets are key to impro...          1.00   \n",
       "3  [MSMARCO, also known as Microsoft Machine Read...          1.00   \n",
       "4  [Paragraph retrieval datasets help in machine ...          0.80   \n",
       "\n",
       "   answer_relevancy  context_relevancy  context_recall  harmfulness  \n",
       "0          0.937075           0.583333             0.0            0  \n",
       "1          1.000000           0.562500             0.0            0  \n",
       "2          0.991355           0.500000             0.0            0  \n",
       "3          0.717319           0.000000             0.0            0  \n",
       "4          0.978917           0.416667             0.5            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "documents = s2reader.load_data(\n",
    "        query=\"datasets for paragraph retrieval\", limit=10\n",
    "    )\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents, service_context=ServiceContext.from_defaults(chunk_size=512)\n",
    ")\n",
    "\n",
    "query_engine = vector_index.as_query_engine()\n",
    "\n",
    "eval_questions = [\n",
    "    \"What is a paragraph retrieval dataset?\",\n",
    "    \"What are some examples of paragraph retrieval datasets?\",\n",
    "    \"Why are paragraph retrieval datasets important?\",\n",
    "    \"What is the MSMARCO dataset used for?\",\n",
    "    \"How can paragraph retrieval datasets help in machine learning?\",\n",
    "]\n",
    "\n",
    "eval_answers = [\n",
    "    \"A paragraph retrieval dataset is a resource used in machine learning and natural language processing that contains various paragraphs, documented to be used in the processes of information retrieval. The dataset can contain paragraphs from a wide variety of topics and could help in tasks like data mining, machine translation, formulation of answers, among others.\",\n",
    "    \"Examples of paragraph retrieval datasets include MSMARCO, SQuAD (Stanford Question Answering Dataset), DeepMind Q&A Dataset, NarrativeQA, and NewsQA. Each of these datasets presents different challenges, like answering complex questions or comprehending written narratives in fine detail.\",\n",
    "    \"Paragraph retrieval datasets are key to improving the accuracy of information retrieval systems and training machines for complex language-related tasks. They enable systems to understand how to locate the most relevant paragraphs to a given query or subject, which is crucial in fields such as digital assistants, search engines, text summarization, and more.\",\n",
    "    \"MSMARCO, also known as Microsoft Machine Reading Comprehension, is a large-scale dataset used in training machine reading comprehension and question answering models. It contains real user queries and manually generated answers, which provide a meaningful challenge to AI models and help improve their real-world performance.\",\n",
    "    \"Paragraph retrieval datasets help in machine learning by providing a resource that can be used to train AI models. These models learn to understand the structure, context, and content within paragraphs and improve their information retrieval capabilities, helping in various tasks including text summarization, text generation, machine translation, recommendation systems, among many others.\",\n",
    "]\n",
    "\n",
    "eval_answers = [[a] for a in eval_answers]\n",
    "result = evaluate(query_engine, metrics, eval_questions, eval_answers)\n",
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:18<00:00, 18.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [harmfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>harmfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What does it mean when we say a language model...</td>\n",
       "      <td>[Biases in Large Language Models: Origins, Inv...</td>\n",
       "      <td>When we say a language model is biased, it mea...</td>\n",
       "      <td>[When we say a language model is biased, we me...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do biases enter large language models?</td>\n",
       "      <td>[Biases in Large Language Models: Origins, Inv...</td>\n",
       "      <td>Biases enter large language models through var...</td>\n",
       "      <td>[Biases enter large language models during the...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.945333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the impact of biases in language models?</td>\n",
       "      <td>[Biases in Large Language Models: Origins, Inv...</td>\n",
       "      <td>The impact of biases in language models can ha...</td>\n",
       "      <td>[The impact of biases in language models is si...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970033</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can we reduce the biases in large language...</td>\n",
       "      <td>[Biases in Large Language Models: Origins, Inv...</td>\n",
       "      <td>There are directions focused on measuring, red...</td>\n",
       "      <td>[Reducing biases in large language models is a...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887473</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What does it mean when we say a language model...   \n",
       "1         How do biases enter large language models?   \n",
       "2   What is the impact of biases in language models?   \n",
       "3  How can we reduce the biases in large language...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Biases in Large Language Models: Origins, Inv...   \n",
       "1  [Biases in Large Language Models: Origins, Inv...   \n",
       "2  [Biases in Large Language Models: Origins, Inv...   \n",
       "3  [Biases in Large Language Models: Origins, Inv...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  When we say a language model is biased, it mea...   \n",
       "1  Biases enter large language models through var...   \n",
       "2  The impact of biases in language models can ha...   \n",
       "3  There are directions focused on measuring, red...   \n",
       "\n",
       "                                       ground_truths  faithfulness  \\\n",
       "0  [When we say a language model is biased, we me...      1.000000   \n",
       "1  [Biases enter large language models during the...      0.888889   \n",
       "2  [The impact of biases in language models is si...      1.000000   \n",
       "3  [Reducing biases in large language models is a...      1.000000   \n",
       "\n",
       "   answer_relevancy  context_relevancy  context_recall  harmfulness  \n",
       "0          1.000000           0.888889             0.0            0  \n",
       "1          0.945333           0.500000             1.0            0  \n",
       "2          0.970033           0.666667             0.0            0  \n",
       "3          0.887473           0.333333             1.0            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = s2reader.load_data(\n",
    "        query=\"biases in large language models\", limit=10\n",
    "    )\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents, service_context=ServiceContext.from_defaults(chunk_size=512)\n",
    ")\n",
    "\n",
    "query_engine = vector_index.as_query_engine()\n",
    "\n",
    "eval_questions = [\n",
    "    \"What does it mean when we say a language model is biased?\",\n",
    "    \"How do biases enter large language models?\",\n",
    "    \"What is the impact of biases in language models?\",\n",
    "    \"How can we reduce the biases in large language models?\",\n",
    "]\n",
    "\n",
    "eval_answers = [\n",
    "    \"When we say a language model is biased, we mean that it exhibits or propagates unfair prejudices in favor or against certain groups, subjects, or ideas. It could unfairly favor one group over another or portray specific groups in harmful or discriminatory ways, reflecting societal or systemic biases.\",\n",
    "    \"Biases enter large language models during their training process. These models are trained on vast amounts of data from the internet, which often include biased content or narratives. As the models learn from this data to predict or generate text, they absorb and encode these biases, perpetuating them in their outputs.\",\n",
    "    \"The impact of biases in language models is significant. Such biases can unintentionally harm individuals or groups that the biases are against by reinforcing stereotypes, spreading misinformation, or promoting discrimination. In addition, they can skew the use of language technologies, affecting decision-making processes in areas like hiring, sentencing, loan approval, and more.\",\n",
    "    \"Reducing biases in large language models is a complex task involving multiple strategies. This can include careful curation of the training set to minimize biased content, utilizing de-biasing techniques during model training, auditing and fine-tuning the model's outputs, and incorporating feedback from a diverse set of users. It also involves ongoing research and attention to the social, ethical, and cultural implications of these computational systems.\",\n",
    "]\n",
    "eval_answers = [[a] for a in eval_answers]\n",
    "result = evaluate(query_engine, metrics, eval_questions, eval_answers)\n",
    "result.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
